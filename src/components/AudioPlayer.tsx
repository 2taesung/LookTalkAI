import React, { useState, useRef, useEffect } from 'react';
import {
  Download,
  Share2,
  Volume2,
  Sparkles,
  Speaker,
  CheckCircle,
  MessageCircle,
  Loader2,
  Facebook,
  Twitter,
  Copy,
  Link as LinkIcon,
} from 'lucide-react';
import { Button } from './ui/Button';
import { createShareableContent } from '../lib/supabaseActions';
import { useToast } from './ToastProvider';
import { useLanguageText } from '../hooks/useLanguageText';
import { detectAudioType, getAudioDuration, getAudioTypeStyles } from '../lib/audioTypes';
import { AUDIO_DURATIONS } from '../constants/audioConfig';
import { getErrorMessage } from '../lib/errorHandler';

interface AudioPlayerProps {
  audioUrl?: string;
  title: string;
  character: string;
  onShare?: () => void;
  onDownload?: () => void;
  isConversation?: boolean;
  autoPlay?: boolean;
  language?: string;
  // ê³µìœ í•  ë¶„ì„ ë°ì´í„°
  analysisData?: {
    imageUrl?: string;
    script?: string;
    timestamp?: number;
    persona?: string;
    audioBlob?: Blob; // audioBlob ì¶”ê°€
  };
}

export function AudioPlayer({
  audioUrl,
  title,
  character,
  onShare,
  onDownload,
  isConversation = false,
  autoPlay = false,
  language = 'en',
  analysisData,
}: AudioPlayerProps) {
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  const [volume, setVolume] = useState(1);
  const [isLoading, setIsLoading] = useState(false);
  const [playbackComplete, setPlaybackComplete] = useState(false);
  const [audioError, setAudioError] = useState<string | null>(null);
  const [hasAutoPlayed, setHasAutoPlayed] = useState(false);
  const [showShareMenu, setShowShareMenu] = useState(false);
  const [isCreatingLink, setIsCreatingLink] = useState(false);

  const audioRef = useRef<HTMLAudioElement>(null);
  const { showToast } = useToast();

  // Use shared utilities for audio type detection and language text
  const audioTypeInfo = detectAudioType(audioUrl);
  const {
    isReactionVoice,
    isSpeechPlaying,
    isDemoAudio,
    isPhotoAnalysisAudio,
    isDebateAudio,
    isRecordedAudio,
    isRealAudio,
    type: audioType,
  } = audioTypeInfo;

  const getText = useLanguageText(language);

  useEffect(() => {
    if (
      !audioUrl ||
      isReactionVoice ||
      isSpeechPlaying ||
      isDemoAudio ||
      isPhotoAnalysisAudio ||
      isDebateAudio
    )
      return;

    const audio = audioRef.current;
    if (!audio) return;

    // ìƒíƒœ ë¦¬ì…‹
    setIsLoading(true);
    setAudioError(null);

    const updateTime = () => {
      setCurrentTime(audio.currentTime);
    };

    const updateDuration = () => {
      setDuration(audio.duration);
      setIsLoading(false);
      console.log('âœ… ì˜¤ë””ì˜¤ ë¡œë“œ ì„±ê³µ, ê¸¸ì´:', audio.duration);

      // ìë™ ì¬ìƒ ë¡œì§
      if (autoPlay && !hasAutoPlayed && audio.duration > 0) {
        console.log('ğŸµ ìë™ ì¬ìƒ ì‹œì‘...');
        setHasAutoPlayed(true);
        setTimeout(() => {
          handleAutoPlay();
        }, 500);
      }
    };

    const handleLoadStart = () => {
      setIsLoading(true);
      console.log('ğŸ”„ ì˜¤ë””ì˜¤ ë¡œë”© ì‹œì‘...');
    };

    const handleCanPlay = () => {
      setIsLoading(false);
      console.log('âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ê°€ëŠ¥');

      if (autoPlay && !hasAutoPlayed) {
        console.log('ğŸµ canplayì—ì„œ ìë™ ì¬ìƒ ì‹œë„...');
        setHasAutoPlayed(true);
        setTimeout(() => {
          handleAutoPlay();
        }, 300);
      }
    };

    const handleEnded = () => {
      setIsPlaying(false);
      setCurrentTime(0);
      setPlaybackComplete(true);
      console.log('âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ');
    };

    const handleError = (e: Event) => {
      const error = (e.target as HTMLAudioElement)?.error;
      console.error('âŒ ì˜¤ë””ì˜¤ ì˜¤ë¥˜:', error);
      setIsLoading(false);
      setAudioError(error?.message || 'ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨');
    };

    const handleLoadedData = () => {
      console.log('ğŸ“Š ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œë¨');
      setIsLoading(false);
    };

    // ëª¨ë“  ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì¶”ê°€
    audio.addEventListener('timeupdate', updateTime);
    audio.addEventListener('loadedmetadata', updateDuration);
    audio.addEventListener('loadeddata', handleLoadedData);
    audio.addEventListener('loadstart', handleLoadStart);
    audio.addEventListener('canplay', handleCanPlay);
    audio.addEventListener('ended', handleEnded);
    audio.addEventListener('error', handleError);

    // ì˜¤ë””ì˜¤ ê°•ì œ ë¡œë“œ
    console.log('ğŸµ ì˜¤ë””ì˜¤ ë¡œë”©:', audioUrl);
    audio.load();

    return () => {
      audio.removeEventListener('timeupdate', updateTime);
      audio.removeEventListener('loadedmetadata', updateDuration);
      audio.removeEventListener('loadeddata', handleLoadedData);
      audio.removeEventListener('loadstart', handleLoadStart);
      audio.removeEventListener('canplay', handleCanPlay);
      audio.removeEventListener('ended', handleEnded);
      audio.removeEventListener('error', handleError);
    };
  }, [
    audioUrl,
    isReactionVoice,
    isSpeechPlaying,
    isDemoAudio,
    isPhotoAnalysisAudio,
    isDebateAudio,
    autoPlay,
  ]);

  // ìë™ ì¬ìƒ í•¨ìˆ˜
  const handleAutoPlay = async () => {
    console.log('ğŸµ ìë™ ì¬ìƒ í•¨ìˆ˜ ì‹¤í–‰...');

    // Handle simulated audio types (non-real audio)
    if (!isRealAudio && audioType !== 'none') {
      const duration = getAudioDuration(audioType);

      if (duration > 0) {
        const typeLabels = {
          'reaction-voice': 'ğŸ™ï¸ Reaction Voice',
          'speech': 'ğŸ¤ ìŒì„± í•©ì„±',
          'photo-analysis': 'ğŸ“¸ ì‚¬ì§„ ë¶„ì„ ì˜¤ë””ì˜¤',
          'debate': 'ğŸ­ í† ë¡  ì˜¤ë””ì˜¤',
          'demo': 'ğŸ­ ë°ëª¨ ì˜¤ë””ì˜¤',
        };

        console.log(`${typeLabels[audioType as keyof typeof typeLabels] || audioType} ìë™ ì¬ìƒ ì‹œì‘`);
        setIsPlaying(true);

        setTimeout(() => {
          setIsPlaying(false);
          setPlaybackComplete(true);
        }, duration);
        return;
      }
    }

    // Handle real audio playback
    const audio = audioRef.current;
    if (!audio || isLoading || audioError) {
      console.log('âŒ ìë™ ì¬ìƒ ë¶ˆê°€:', {
        audio: !!audio,
        isLoading,
        audioError,
      });
      return;
    }

    try {
      console.log('â–¶ï¸ ì‹¤ì œ ì˜¤ë””ì˜¤ ìë™ ì¬ìƒ ì‹œì‘');

      if (audio.readyState < 2) {
        console.log('ğŸ”„ ì˜¤ë””ì˜¤ ì¤€ë¹„ ëŒ€ê¸° ì¤‘...');
        await new Promise((resolve, reject) => {
          const timeout = setTimeout(() => {
            reject(new Error('ìë™ ì¬ìƒì„ ìœ„í•œ ì˜¤ë””ì˜¤ ë¡œë”© íƒ€ì„ì•„ì›ƒ'));
          }, 5000);

          const onCanPlay = () => {
            clearTimeout(timeout);
            audio.removeEventListener('canplay', onCanPlay);
            audio.removeEventListener('error', onError);
            resolve(void 0);
          };

          const onError = () => {
            clearTimeout(timeout);
            audio.removeEventListener('canplay', onCanPlay);
            audio.removeEventListener('error', onError);
            reject(new Error('ìë™ ì¬ìƒì„ ìœ„í•œ ì˜¤ë””ì˜¤ ë¡œë”© ì‹¤íŒ¨'));
          };

          audio.addEventListener('canplay', onCanPlay, { once: true });
          audio.addEventListener('error', onError, { once: true });
        });
      }

      await audio.play();
      setIsPlaying(true);
      setPlaybackComplete(false);
      console.log('âœ… ìë™ ì¬ìƒ ì„±ê³µ!');
    } catch (error) {
      console.error('âŒ ìë™ ì¬ìƒ ì‹¤íŒ¨:', error);
    }
  };

  // autoPlay propì´ ë³€ê²½ë  ë•Œ ìë™ ì¬ìƒ ì‹œë„
  useEffect(() => {
    if (
      autoPlay &&
      !hasAutoPlayed &&
      isRealAudio &&
      !isLoading &&
      !audioError
    ) {
      console.log('ğŸµ autoPlay prop ë³€ê²½ìœ¼ë¡œ ìë™ ì¬ìƒ ì‹œë„...');
      setHasAutoPlayed(true);
      setTimeout(() => {
        handleAutoPlay();
      }, 1000);
    }
  }, [autoPlay, hasAutoPlayed, isRealAudio, isLoading, audioError]);

  // íŠ¹ìˆ˜ ì˜¤ë””ì˜¤ íƒ€ì…ì˜ ê²½ìš° ì¦‰ì‹œ ìë™ ì¬ìƒ
  useEffect(() => {
    if (
      autoPlay &&
      !hasAutoPlayed &&
      (isReactionVoice ||
        isSpeechPlaying ||
        isDemoAudio ||
        isPhotoAnalysisAudio ||
        isDebateAudio)
    ) {
      console.log('ğŸµ íŠ¹ìˆ˜ ì˜¤ë””ì˜¤ íƒ€ì… ìë™ ì¬ìƒ...');
      setHasAutoPlayed(true);
      setTimeout(() => {
        handleAutoPlay();
      }, 500);
    }
  }, [
    autoPlay,
    hasAutoPlayed,
    isReactionVoice,
    isSpeechPlaying,
    isDemoAudio,
    isPhotoAnalysisAudio,
    isDebateAudio,
  ]);

  const handlePlayPause = async () => {
    // Handle simulated audio types (non-real audio)
    if (!isRealAudio && audioType !== 'none') {
      const duration = getAudioDuration(audioType);

      if (duration > 0) {
        const typeLabels = {
          'reaction-voice': `ğŸ™ï¸ Reaction Voice ì¬ìƒ: ${character}`,
          'speech': `ğŸ¤ ìŒì„± í•©ì„±ì´ ì´ë¯¸ ${character}ë¡œ ì¬ìƒ ì¤‘`,
          'photo-analysis': `ğŸ“¸ ${character} ì‚¬ì§„ ë¶„ì„ ì˜¤ë””ì˜¤ ì¬ìƒ`,
          'debate': `ğŸ­ ${character} í† ë¡  ì˜¤ë””ì˜¤ ì¬ìƒ`,
          'demo': `ğŸ­ ${character} ë°ëª¨ ì˜¤ë””ì˜¤ ì¬ìƒ`,
        };

        console.log(typeLabels[audioType as keyof typeof typeLabels] || audioType);
        setIsPlaying(!isPlaying);

        if (!isPlaying) {
          setTimeout(() => {
            setIsPlaying(false);
            setPlaybackComplete(true);
          }, duration);
        }
        return;
      }
    }

    // Handle real audio playback
    const audio = audioRef.current;
    if (!audio || isLoading) return;

    try {
      if (isPlaying) {
        console.log('â¸ï¸ ì˜¤ë””ì˜¤ ì¼ì‹œì •ì§€');
        audio.pause();
        setIsPlaying(false);
      } else {
        console.log('â–¶ï¸ ì˜¤ë””ì˜¤ ì¬ìƒ');

        setAudioError(null);

        if (audio.readyState < 2) {
          console.log('ğŸ”„ ì˜¤ë””ì˜¤ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ, ë¡œë”©...');
          setIsLoading(true);
          audio.load();

          await new Promise((resolve, reject) => {
            const timeout = setTimeout(() => {
              reject(new Error('ì˜¤ë””ì˜¤ ë¡œë”© íƒ€ì„ì•„ì›ƒ'));
            }, 10000);

            const onCanPlay = () => {
              clearTimeout(timeout);
              audio.removeEventListener('canplay', onCanPlay);
              audio.removeEventListener('error', onError);
              resolve(void 0);
            };

            const onError = () => {
              clearTimeout(timeout);
              audio.removeEventListener('canplay', onCanPlay);
              audio.removeEventListener('error', onError);
              reject(new Error('ì˜¤ë””ì˜¤ ë¡œë”© ì‹¤íŒ¨'));
            };

            audio.addEventListener('canplay', onCanPlay, { once: true });
            audio.addEventListener('error', onError, { once: true });
          });
        }

        await audio.play();
        setIsPlaying(true);
        setPlaybackComplete(false);
        setIsLoading(false);
        console.log('âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì„±ê³µ');
      }
    } catch (error) {
      console.error('âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', error);
      setIsPlaying(false);
      setIsLoading(false);
      setAudioError(getErrorMessage(error));
    }
  };

  const handleSeek = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (
      isDemoAudio ||
      isSpeechPlaying ||
      isReactionVoice ||
      isPhotoAnalysisAudio ||
      isDebateAudio
    )
      return;

    const audio = audioRef.current;
    if (!audio) return;

    const newTime = parseFloat(e.target.value);
    audio.currentTime = newTime;
    setCurrentTime(newTime);
  };

  const handleVolumeChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const newVolume = parseFloat(e.target.value);
    setVolume(newVolume);
    if (audioRef.current) {
      audioRef.current.volume = newVolume;
    }
  };

  const handleDownload = () => {
    if (audioUrl && onDownload && isRealAudio) {
      const link = document.createElement('a');
      link.href = audioUrl;
      const filename = `LookTalkAI_${character}_${Date.now()}.mp3`;
      link.download = filename;
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
    } else {
      // ì‹¤ì œ ì˜¤ë””ì˜¤ê°€ ì—†ëŠ” ê²½ìš° ì‹œë®¬ë ˆì´ì…˜
      console.log('ğŸµ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜');
      const blob = new Blob(['Audio MP3 content'], { type: 'audio/mpeg' });
      const url = URL.createObjectURL(blob);
      const link = document.createElement('a');
      link.href = url;
      link.download = `LookTalkAI_${character}_${Date.now()}.mp3`;
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
      URL.revokeObjectURL(url);
    }
  };

  // ê³µìœ  ë§í¬ ìƒì„± í•¨ìˆ˜
  const generateShareLink = async (): Promise<string> => {
    console.log('ğŸ”— generateShareLink ì‹œì‘, analysisData:', analysisData);
    
    if (analysisData) {
      // ë¡œë”© ìƒíƒœ ì‹œì‘
      setIsCreatingLink(true);
      try {
        console.log('âœ… analysisData ì¡´ì¬í•¨, ê³µìœ  ë§í¬ ìƒì„± ì‹œì‘');
        let finalAudioUrl = audioUrl || '';
        
        // analysisDataì— audioBlobì´ ìˆìœ¼ë©´ ì´ë¥¼ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ blob URLì—ì„œ ê°€ì ¸ì˜¤ê¸°
        let audioBlob = analysisData.audioBlob;
        
        if (!audioBlob && finalAudioUrl && finalAudioUrl.startsWith('blob:')) {
          console.log('ğŸ”„ Blob URLì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° ì¶”ì¶œ ì¤‘...');
          try {
            const response = await fetch(finalAudioUrl);
            audioBlob = await response.blob();
          } catch (error) {
            console.error('âŒ Blob URLì—ì„œ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨:', error);
            throw new Error('ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
          }
        }
        
        // audioBlobì´ ìˆìœ¼ë©´ Supabase Storageì— ì—…ë¡œë“œ
        if (audioBlob) {
          console.log('ğŸ”„ ì˜¤ë””ì˜¤ íŒŒì¼ì„ Supabase Storageì— ì—…ë¡œë“œ ì¤‘...');
          
          console.log('ğŸµ ì˜¤ë””ì˜¤ Blob ì •ë³´:', {
            size: audioBlob.size,
            type: audioBlob.type,
            sizeInKB: Math.round(audioBlob.size / 1024)
          });
          
          // íŒŒì¼ í¬ê¸° ê²€ì¦
          if (audioBlob.size < 1024) {
            throw new Error('ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
          }
          
          // Supabase Storageì— ì—…ë¡œë“œ
          const { supabase } = await import('../lib/supabaseClient');
          const audioFilePath = `public/shared-audio-${Date.now()}.mp3`;
          
          const { data: uploadData, error: uploadError } = await supabase.storage
            .from('media')
            .upload(audioFilePath, audioBlob, { 
              contentType: 'audio/mpeg',
              cacheControl: '3600',
              upsert: false
            });
          
          if (uploadError) {
            console.error('âŒ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì‹¤íŒ¨:', uploadError);
            throw new Error(`ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì‹¤íŒ¨: ${uploadError.message}`);
          }
          
          // ì—…ë¡œë“œëœ íŒŒì¼ì˜ public URL ìƒì„±
          const { data: { publicUrl } } = supabase.storage
            .from('media')
            .getPublicUrl(audioFilePath);
          
          finalAudioUrl = publicUrl;
          console.log('âœ… ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì™„ë£Œ, Public URL:', finalAudioUrl);
        } else {
          console.warn('âš ï¸ ì—…ë¡œë“œí•  ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
        }

        // Supabaseì— ì €ì¥í•  ë°ì´í„° ê°ì²´ ìƒì„±
        const contentData = {
          image_url: analysisData.imageUrl || '',
          audio_url: finalAudioUrl,
          script: title, // titleì„ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‚¬ìš©
          persona: analysisData.persona || '', // persona ì¶”ê°€
        };

        console.log('ğŸ“ DBì— ì €ì¥í•  ë°ì´í„°:', contentData);

        // lib/supabaseActions.tsì˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ DBì— ì €ì¥í•˜ê³  IDë¥¼ ë°›ìŒ
        console.log('ğŸ’¾ createShareableContent í˜¸ì¶œ ì¤‘...');
        const shareId = await createShareableContent(contentData);
        console.log('âœ… DB ì €ì¥ ì™„ë£Œ, shareId:', shareId);

        // ê³µìœ  URL ìƒì„± (ì‹¤ì œ ë°°í¬ëœ ë„ë©”ì¸ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤)
        const baseUrl = window.location.origin;
        const shareUrl = `${baseUrl}/shared/${shareId}`;
        console.log('ğŸ‰ ê³µìœ  ë§í¬ ìƒì„± ì™„ë£Œ:', shareUrl);

        return shareUrl;
      } catch (error) {
        console.error('âŒ ê³µìœ  ë§í¬ ìƒì„± ì‹¤íŒ¨:', error);
        showToast({
          message: getText(
            'ê³µìœ  ë§í¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
            'Failed to create share link.',
            'åˆ›å»ºåˆ†äº«é“¾æ¥å¤±è´¥ã€‚'
          ),
          type: 'error',
          duration: 3000
        });
        return '';
      } finally {
        // ë¡œë”© ìƒíƒœ ì¢…ë£Œ
        setIsCreatingLink(false);
      }
    }

    // ë¶„ì„ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
    console.warn('âŒ ë¶„ì„ ë°ì´í„°ê°€ ì—†ì–´ ê³µìœ  ë§í¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    console.log('í˜„ì¬ analysisData:', analysisData);
    console.log('í˜„ì¬ audioUrl:', audioUrl);
    showToast({
      message: getText(
        'ê³µìœ í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‚¬ì§„ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.',
        'No data to share. Please analyze a photo first.',
        'æ²¡æœ‰è¦åˆ†äº«çš„æ•°æ®ã€‚è¯·å…ˆåˆ†æç…§ç‰‡ã€‚'
      ),
      type: 'error',
      duration: 3000
    });
    return '';
  };

  const handleShare = () => {
    setShowShareMenu(!showShareMenu);
  };

  const shareToFacebook = async () => {
    const shareUrl = await generateShareLink();
    if (shareUrl === window.location.href && !analysisData) return;

    const url = `https://www.facebook.com/sharer/sharer.php?u=${encodeURIComponent(
      shareUrl
    )}`;
    window.open(url, '_blank', 'width=600,height=400');
    setShowShareMenu(false);
  };

  const shareToTwitter = async () => {
    const shareUrl = await generateShareLink();
    if (shareUrl === window.location.href && !analysisData) return;
    const text = analysisData
      ? `LookTalkAI - ${character}ì˜ AI ì‚¬ì§„ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”!`
      : `LookTalkAI - AI Photo Analysis: ${title}`;
    const url = `https://twitter.com/intent/tweet?text=${encodeURIComponent(
      text
    )}&url=${encodeURIComponent(shareUrl)}`;
    window.open(url, '_blank', 'width=600,height=400');
    setShowShareMenu(false);
  };

  const copyLink = async () => {
    const shareUrl = await generateShareLink();
    if (shareUrl === window.location.href && !analysisData) return;

    try {
      await navigator.clipboard?.writeText(shareUrl);
      
      // í† ìŠ¤íŠ¸ ì•Œë¦¼ í‘œì‹œ
      showToast({
        message: getText(
          'ë¶„ì„ ê²°ê³¼ ë§í¬ê°€ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!',
          'Analysis result link copied!',
          'åˆ†æç»“æœé“¾æ¥å·²å¤åˆ¶ï¼'
        ),
        type: 'success',
        duration: 3000
      });
      
      setShowShareMenu(false);
    } catch (error) {
      console.error('í´ë¦½ë³´ë“œ ë³µì‚¬ ì‹¤íŒ¨:', error);
      showToast({
        message: getText(
          'ë§í¬ ë³µì‚¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
          'Failed to copy link.',
          'å¤åˆ¶é“¾æ¥å¤±è´¥ã€‚'
        ),
        type: 'error',
        duration: 3000
      });
    }
  };

  const formatTime = (time: number) => {
    if (isNaN(time)) return '0:00';
    const minutes = Math.floor(time / 60);
    const seconds = Math.floor(time % 60);
    return `${minutes}:${seconds.toString().padStart(2, '0')}`;
  };

  if (!audioUrl) {
    return (
      <div className="p-4 sm:p-6 text-center text-gray-500">
        <Volume2 className="w-8 h-8 sm:w-12 sm:h-12 mx-auto mb-2 sm:mb-3 opacity-50" />
        <p className="text-sm sm:text-base">
          {getText(
            'ì˜¤ë””ì˜¤ê°€ ìƒì„±ë˜ë©´ ì—¬ê¸°ì— ë‚˜íƒ€ë‚©ë‹ˆë‹¤',
            'Audio will appear here when generated',
            'ç”ŸæˆéŸ³é¢‘åå°†åœ¨æ­¤å¤„æ˜¾ç¤º'
          )}
        </p>
      </div>
    );
  }

  return (
    <div className="space-y-3 sm:space-y-4">
      {isRealAudio && (
        <audio
          ref={audioRef}
          src={audioUrl}
          preload="metadata"
          crossOrigin="anonymous"
        />
      )}

      {/* ì˜¤ë””ì˜¤ ìƒíƒœ */}
      <div
        className={`p-2 sm:p-3 rounded-lg border ${
          audioError
            ? 'bg-red-50 border-red-200'
            : playbackComplete
            ? 'bg-green-50 border-green-200'
            : isReactionVoice
            ? 'bg-gradient-to-r from-purple-50 to-blue-50 border-purple-200'
            : isSpeechPlaying
            ? 'bg-blue-50 border-blue-200'
            : isPhotoAnalysisAudio
            ? 'bg-gradient-to-r from-orange-50 to-yellow-50 border-orange-200'
            : isDebateAudio
            ? 'bg-gradient-to-r from-red-50 to-purple-50 border-red-200'
            : 'bg-gradient-to-r from-green-50 to-blue-50 border-green-200'
        }`}
      >
        <div className="flex items-center space-x-2">
          {audioError ? (
            <div className="w-3 h-3 sm:w-4 sm:h-4 text-red-600">âš ï¸</div>
          ) : playbackComplete ? (
            <CheckCircle className="w-3 h-3 sm:w-4 sm:h-4 text-green-600" />
          ) : isReactionVoice ? (
            <MessageCircle className="w-3 h-3 sm:w-4 sm:h-4 text-purple-600" />
          ) : isSpeechPlaying ? (
            <div className="w-3 h-3 sm:w-4 sm:h-4 text-blue-600">ğŸ¤</div>
          ) : isPhotoAnalysisAudio ? (
            <div className="w-3 h-3 sm:w-4 sm:h-4 text-orange-600">ğŸ“¸</div>
          ) : isDebateAudio ? (
            <div className="w-3 h-3 sm:w-4 sm:h-4 text-red-600">ğŸ­</div>
          ) : (
            <Speaker className="w-3 h-3 sm:w-4 sm:h-4 text-blue-600" />
          )}
          <span className="text-xs sm:text-sm font-medium text-gray-700">
            {audioError
              ? getText(
                  `Audio error: ${audioError}`,
                  `Audio error: ${audioError}`,
                  `éŸ³é¢‘é”™è¯¯: ${audioError}`
                )
              : isReactionVoice
              ? getText(
                  `ğŸ­ Reaction Voice: ë‚´ë ˆì´í„° + ${character} (í•˜ë‚˜ì˜ MP3)`,
                  `ğŸ­ Reaction Voice: Narrator + ${character} (One MP3)`,
                  `ğŸ­ Reaction Voice: æ—ç™½ + ${character} (ä¸€ä¸ªMP3)`
                )
              : isSpeechPlaying
              ? getText(
                  `${character} voice playing (Browser TTS)`,
                  `${character} voice playing (Browser TTS)`,
                  `${character} è¯­éŸ³æ’­æ”¾ä¸­ (æµè§ˆå™¨TTS)`
                )
              : isPhotoAnalysisAudio
              ? getText(
                  `ğŸ“¸ Photo Analysis: ${character} Voice Narration`,
                  `ğŸ“¸ Photo Analysis: ${character} Voice Narration`,
                  `ğŸ“¸ ç…§ç‰‡åˆ†æ: ${character} è¯­éŸ³æ—ç™½`
                )
              : isDebateAudio
              ? getText(
                  `ğŸ­ Debate Audio: ${character} Mixed Voices`,
                  `ğŸ­ Debate Audio: ${character} Mixed Voices`,
                  `ğŸ­ è¾©è®ºéŸ³é¢‘: ${character} æ··åˆè¯­éŸ³`
                )
              : isDemoAudio
              ? getText(
                  `${character} Voice Demo`,
                  `${character} Voice Demo`,
                  `${character} è¯­éŸ³æ¼”ç¤º`
                )
              : getText(
                  `Enhanced ${character} Voice`,
                  `Enhanced ${character} Voice`,
                  `å¢å¼ºçš„ ${character} è¯­éŸ³`
                )}
          </span>
          {playbackComplete && !audioError && (
            <span className="text-xs text-green-600 bg-green-100 px-1.5 sm:px-2 py-0.5 sm:py-1 rounded-full">
              âœ“ {getText('ì¬ìƒë¨', 'Played', 'å·²æ’­æ”¾')}
            </span>
          )}
        </div>
        <p className="text-xs mt-1 text-gray-600">
          {audioError
            ? getText(
                'Please refresh the page or regenerate',
                'Please refresh the page or regenerate',
                'è¯·åˆ·æ–°é¡µé¢æˆ–é‡æ–°ç”Ÿæˆ'
              )
            : isReactionVoice
            ? getText(
                'ğŸ­ Reaction Voice: Record narrator voice and character reactions, mix into one MP3',
                'ğŸ­ Reaction Voice: Record narrator voice and character reactions, mix into one MP3',
                'ğŸ­ Reaction Voice: å½•åˆ¶æ—ç™½è¯­éŸ³å’Œè§’è‰²ååº”ï¼Œæ··åˆæˆä¸€ä¸ªMP3'
              )
            : isSpeechPlaying
            ? getText(
                `ğŸ¤ ${character} voice plays directly through browser`,
                `ğŸ¤ ${character} voice plays directly through browser`,
                `ğŸ¤ ${character} è¯­éŸ³é€šè¿‡æµè§ˆå™¨ç›´æ¥æ’­æ”¾`
              )
            : isPhotoAnalysisAudio
            ? getText(
                `${character} analyzes and describes the photo with voice narration`,
                `${character} analyzes and describes the photo with voice narration`,
                `${character} åˆ†æå¹¶ç”¨è¯­éŸ³æ—ç™½æè¿°ç…§ç‰‡`
              )
            : isDebateAudio
            ? getText(
                `ğŸ­ ${character} debate with mixed persona voices in one audio file`,
                `ğŸ­ ${character} debate with mixed persona voices in one audio file`,
                `ğŸ­ ${character} è¾©è®ºï¼Œå¤šä¸ªè§’è‰²è¯­éŸ³æ··åˆåœ¨ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ä¸­`
              )
            : isDemoAudio
            ? getText(
                'Voice synthesis complete - click play to hear character voice',
                'Voice synthesis complete - click play to hear character voice',
                'è¯­éŸ³åˆæˆå®Œæˆ - ç‚¹å‡»æ’­æ”¾å¬å–è§’è‰²è¯­éŸ³'
              )
            : isRecordedAudio
            ? getText(
                'Actually recorded character voice with enhanced script',
                'Actually recorded character voice with enhanced script',
                'ä½¿ç”¨å¢å¼ºè„šæœ¬å®é™…å½•åˆ¶çš„è§’è‰²è¯­éŸ³'
              )
            : getText(
                'High-quality character voice with enhanced script',
                'High-quality character voice with enhanced script',
                'ä½¿ç”¨å¢å¼ºè„šæœ¬çš„é«˜è´¨é‡è§’è‰²è¯­éŸ³'
              )}
        </p>
      </div>

      {/* íŒŒí˜• ì‹œê°í™” */}
      <div className="h-12 sm:h-16 bg-gradient-to-r from-purple-100 to-teal-100 rounded-lg flex items-center justify-center relative overflow-hidden">
        {isLoading ? (
          <div className="flex items-center space-x-2">
            <div className="animate-spin w-4 h-4 sm:w-5 sm:h-5 border-2 border-purple-600 border-t-transparent rounded-full" />
            <span className="text-xs sm:text-sm text-purple-600">
              {getText(
                isConversation
                  ? 'Generating Reaction Voice...'
                  : isPhotoAnalysisAudio
                  ? 'Generating photo analysis audio...'
                  : isDebateAudio
                  ? 'Generating debate audio...'
                  : `Loading ${character} voice...`,
                isConversation
                  ? 'Generating Reaction Voice...'
                  : isPhotoAnalysisAudio
                  ? 'Generating photo analysis audio...'
                  : isDebateAudio
                  ? 'Generating debate audio...'
                  : `Loading ${character} voice...`,
                isConversation
                  ? 'æ­£åœ¨ç”ŸæˆReaction Voice...'
                  : isPhotoAnalysisAudio
                  ? 'æ­£åœ¨ç”Ÿæˆç…§ç‰‡åˆ†æéŸ³é¢‘...'
                  : isDebateAudio
                  ? 'æ­£åœ¨ç”Ÿæˆè¾©è®ºéŸ³é¢‘...'
                  : `æ­£åœ¨åŠ è½½ ${character} è¯­éŸ³...`
              )}
            </span>
          </div>
        ) : audioError ? (
          <div className="flex items-center space-x-2 text-red-600">
            <span className="text-xs sm:text-sm">
              âš ï¸ {getText('Audio Error', 'Audio Error', 'éŸ³é¢‘é”™è¯¯')}
            </span>
          </div>
        ) : (
          <div className="flex items-end space-x-0.5 sm:space-x-1">
            {Array.from({ length: 30 }, (_, i) => (
              <div
                key={i}
                className={`w-0.5 sm:w-1 rounded-full transition-all duration-300 ${
                  isConversation
                    ? 'bg-gradient-to-t from-blue-400 via-purple-400 to-teal-400' // Reaction Voiceìš© ê·¸ë¼ë°ì´ì…˜
                    : isReactionVoice
                    ? 'bg-gradient-to-t from-purple-400 via-blue-400 to-teal-400'
                    : isPhotoAnalysisAudio
                    ? 'bg-gradient-to-t from-orange-400 via-yellow-400 to-red-400'
                    : isDebateAudio
                    ? 'bg-gradient-to-t from-red-400 via-purple-400 to-blue-400'
                    : 'bg-gradient-to-t from-purple-400 to-teal-400'
                } ${
                  isDemoAudio ||
                  isSpeechPlaying ||
                  isReactionVoice ||
                  isPhotoAnalysisAudio ||
                  isDebateAudio
                    ? isPlaying
                      ? 'opacity-100 scale-110'
                      : 'opacity-30'
                    : isRealAudio && duration > 0
                    ? (currentTime / duration) * 30 > i
                      ? 'opacity-100 scale-110'
                      : 'opacity-30'
                    : 'opacity-30'
                } ${isPlaying ? 'animate-pulse' : ''}`}
                style={{
                  height: `${Math.random() * 30 + 6}px`,
                  animationDelay: `${i * 0.05}s`,
                }}
              />
            ))}
          </div>
        )}
      </div>

      {/* ì»¨íŠ¸ë¡¤ */}
      <div className="flex items-center space-x-3 sm:space-x-4">
        <Button
          onClick={handlePlayPause}
          disabled={isLoading || !!audioError}
          className="rounded-full w-12 h-12 sm:w-10 sm:h-10 p-0 relative flex items-center justify-center min-w-[48px] min-h-[48px] sm:min-w-[40px] sm:min-h-[40px]"
        >
          {isLoading ? (
            <div
              className="animate-spin rounded-full"
              style={{
                width: '20px',
                height: '20px',
                border: '2px solid #ffffff',
                borderTop: '2px solid transparent',
              }}
            />
          ) : isPlaying ? (
            <svg
              viewBox="0 0 24 24"
              width="20"
              height="20"
              style={{
                fill: '#ffffff',
                minWidth: '20px',
                minHeight: '20px',
                filter: 'drop-shadow(0 1px 2px rgba(0, 0, 0, 0.2))',
              }}
            >
              <path d="M6 19h4V5H6v14zm8-14v14h4V5h-4z"></path>
            </svg>
          ) : (
            <svg
              viewBox="0 0 24 24"
              width="20"
              height="20"
              style={{
                fill: '#ffffff',
                marginLeft: '2px',
                minWidth: '20px',
                minHeight: '20px',
                filter: 'drop-shadow(0 1px 2px rgba(0, 0, 0, 0.2))',
              }}
            >
              <path d="M8 5v14l11-7z"></path>
            </svg>
          )}
        </Button>

        <div className="flex-1 space-y-1 sm:space-y-2">
          {isRealAudio && !audioError && (
            <>
              <input
                type="range"
                min={0}
                max={duration || 0}
                value={currentTime}
                onChange={handleSeek}
                disabled={isLoading || !!audioError}
                className="w-full h-1.5 sm:h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer slider disabled:opacity-50"
                style={{
                  background: `linear-gradient(to right, #8B5CF6 0%, #8B5CF6 ${
                    duration > 0 ? (currentTime / duration) * 100 : 0
                  }%, #e5e7eb ${
                    duration > 0 ? (currentTime / duration) * 100 : 0
                  }%, #e5e7eb 100%)`,
                }}
              />
              <div className="flex justify-between text-xs text-gray-500">
                <span>{formatTime(currentTime)}</span>
                <span>{formatTime(duration)}</span>
              </div>
            </>
          )}
          {(isDemoAudio ||
            isSpeechPlaying ||
            isReactionVoice ||
            isPhotoAnalysisAudio ||
            isDebateAudio ||
            audioError) && (
            <div className="text-center">
              <div className="text-xs sm:text-sm text-gray-600">
                {audioError
                  ? getText(
                      'âŒ Audio playback failed',
                      'âŒ Audio playback failed',
                      'âŒ éŸ³é¢‘æ’­æ”¾å¤±è´¥'
                    )
                  : isReactionVoice
                  ? getText(
                      isPlaying
                        ? 'ğŸ­ Reaction Voice MP3 playing...'
                        : 'ğŸ­ Reaction Voice ready to play',
                      isPlaying
                        ? 'ğŸ­ Reaction Voice MP3 playing...'
                        : 'ğŸ­ Reaction Voice ready to play',
                      isPlaying
                        ? 'ğŸ­ Reaction Voice MP3 æ’­æ”¾ä¸­...'
                        : 'ğŸ­ Reaction Voice å‡†å¤‡æ’­æ”¾'
                    )
                  : isSpeechPlaying
                  ? getText(
                      isPlaying
                        ? 'ğŸ¤ Playing through browser speakers...'
                        : 'ğŸ¤ Ready to play through speakers',
                      isPlaying
                        ? 'ğŸ¤ Playing through browser speakers...'
                        : 'ğŸ¤ Ready to play through speakers',
                      isPlaying
                        ? 'ğŸ¤ é€šè¿‡æµè§ˆå™¨æ‰¬å£°å™¨æ’­æ”¾ä¸­...'
                        : 'ğŸ¤ å‡†å¤‡é€šè¿‡æ‰¬å£°å™¨æ’­æ”¾'
                    )
                  : isPhotoAnalysisAudio
                  ? getText(
                      isPlaying
                        ? 'ğŸ“¸ Photo analysis audio playing...'
                        : 'ğŸ“¸ Photo analysis audio ready',
                      isPlaying
                        ? 'ğŸ“¸ Photo analysis audio playing...'
                        : 'ğŸ“¸ Photo analysis audio ready',
                      isPlaying
                        ? 'ğŸ“¸ ç…§ç‰‡åˆ†æéŸ³é¢‘æ’­æ”¾ä¸­...'
                        : 'ğŸ“¸ ç…§ç‰‡åˆ†æéŸ³é¢‘å‡†å¤‡å°±ç»ª'
                    )
                  : isDebateAudio
                  ? getText(
                      isPlaying
                        ? 'ğŸ­ Debate audio playing...'
                        : 'ğŸ­ Debate audio ready',
                      isPlaying
                        ? 'ğŸ­ Debate audio playing...'
                        : 'ğŸ­ Debate audio ready',
                      isPlaying
                        ? 'ğŸ­ è¾©è®ºéŸ³é¢‘æ’­æ”¾ä¸­...'
                        : 'ğŸ­ è¾©è®ºéŸ³é¢‘å‡†å¤‡å°±ç»ª'
                    )
                  : getText(
                      isPlaying
                        ? 'ğŸ¤ Character voice playing...'
                        : 'ğŸ­ Ready to play',
                      isPlaying
                        ? 'ğŸ¤ Character voice playing...'
                        : 'ğŸ­ Ready to play',
                      isPlaying ? 'ğŸ¤ è§’è‰²è¯­éŸ³æ’­æ”¾ä¸­...' : 'ğŸ­ å‡†å¤‡æ’­æ”¾'
                    )}
              </div>
              <div className="text-xs text-gray-500 mt-1">
                {audioError
                  ? getText(
                      'Please refresh the page or regenerate',
                      'Please refresh the page or regenerate',
                      'è¯·åˆ·æ–°é¡µé¢æˆ–é‡æ–°ç”Ÿæˆ'
                    )
                  : isReactionVoice
                  ? getText(
                      `Reaction Voice: Record narrator voice + ${character} reactions and mix into one MP3`,
                      `Reaction Voice: Record narrator voice + ${character} reactions and mix into one MP3`,
                      `Reaction Voice: å½•åˆ¶æ—ç™½è¯­éŸ³ + ${character} ååº”å¹¶æ··åˆæˆä¸€ä¸ªMP3`
                    )
                  : isSpeechPlaying
                  ? getText(
                      `${character} voice plays directly through browser`,
                      `${character} voice plays directly through browser`,
                      `${character} è¯­éŸ³é€šè¿‡æµè§ˆå™¨ç›´æ¥æ’­æ”¾`
                    )
                  : isPhotoAnalysisAudio
                  ? getText(
                      `${character} analyzes and describes the photo with voice narration`,
                      `${character} analyzes and describes the photo with voice narration`,
                      `${character} åˆ†æå¹¶ç”¨è¯­éŸ³æ—ç™½æè¿°ç…§ç‰‡`
                    )
                  : isDebateAudio
                  ? getText(
                      `${character} debate with multiple persona voices mixed into one audio`,
                      `${character} debate with multiple persona voices mixed into one audio`,
                      `${character} è¾©è®ºï¼Œå¤šä¸ªè§’è‰²è¯­éŸ³æ··åˆæˆä¸€ä¸ªéŸ³é¢‘`
                    )
                  : getText(
                      `Enhanced script reading with ${character} voice characteristics`,
                      `Enhanced script reading with ${character} voice characteristics`,
                      `ä½¿ç”¨ ${character} è¯­éŸ³ç‰¹æ€§çš„å¢å¼ºè„šæœ¬é˜…è¯»`
                    )}
              </div>
            </div>
          )}
        </div>

        {isRealAudio && !audioError && (
          <div className="hidden sm:flex items-center space-x-2">
            <Volume2 className="w-3 h-3 sm:w-4 sm:h-4 text-gray-500" />
            <input
              type="range"
              min={0}
              max={1}
              step={0.1}
              value={volume}
              onChange={handleVolumeChange}
              className="w-12 sm:w-16 h-1.5 sm:h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer slider"
              style={{
                background: `linear-gradient(to right, #8B5CF6 0%, #8B5CF6 ${
                  volume * 100
                }%, #e5e7eb ${volume * 100}%, #e5e7eb 100%)`,
              }}
            />
          </div>
        )}
      </div>

      {/* ì•¡ì…˜ */}
      <div className="flex flex-col sm:flex-row gap-2 sm:gap-3">
        <div className="relative flex-1">
          <Button
            variant="outline"
            size="sm"
            onClick={handleShare}
            className="w-full text-xs sm:text-sm"
            disabled={isCreatingLink}
          >
            {isCreatingLink ? (
              <Loader2 className="w-3 h-3 sm:w-4 sm:h-4 mr-2 animate-spin" />
            ) : (
              <Share2 className="w-3 h-3 sm:w-4 sm:h-4 mr-2" />
            )}
            {isCreatingLink
              ? getText('ìƒì„± ì¤‘...', 'Creating...', 'åˆ›å»ºä¸­...')
              : getText('ê³µìœ ', 'Share', 'åˆ†äº«')}
          </Button>

          {/* ê³µìœ  ë©”ë‰´ */}
          {showShareMenu && (
            <div className="absolute bottom-full left-0 right-0 mb-2 bg-white rounded-lg shadow-lg border border-gray-200 py-2 z-50">
              <button
                onClick={shareToFacebook}
                disabled={isCreatingLink}
                className="w-full px-4 py-2 text-left text-sm hover:bg-gray-50 flex items-center space-x-2 disabled:opacity-50"
              >
                <Facebook className="w-4 h-4 text-blue-600" />
                <span>Facebook</span>
              </button>
              <button
                onClick={shareToTwitter}
                disabled={isCreatingLink}
                className="w-full px-4 py-2 text-left text-sm hover:bg-gray-50 flex items-center space-x-2 disabled:opacity-50"
              >
                <Twitter className="w-4 h-4 text-blue-400" />
                <span>Twitter</span>
              </button>
              <button
                onClick={copyLink}
                disabled={isCreatingLink}
                className="w-full px-4 py-2 text-left text-sm hover:bg-gray-50 flex items-center space-x-2 disabled:opacity-50"
              >
                <Copy className="w-4 h-4 text-gray-600" />
                <span>{getText('ë§í¬ ë³µì‚¬', 'Copy Link', 'å¤åˆ¶é“¾æ¥')}</span>
              </button>
            </div>
          )}
        </div>
        <Button
          variant="outline"
          size="sm"
          onClick={handleDownload}
          className="flex-1 text-xs sm:text-sm"
        >
          <Download className="w-3 h-3 sm:w-4 sm:h-4 mr-2" />
          <span className="hidden sm:inline">
            {getText(
              isConversation
                ? 'Reaction Voice ë‹¤ìš´ë¡œë“œ'
                : isPhotoAnalysisAudio
                ? 'ì‚¬ì§„ ë¶„ì„ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ'
                : isDebateAudio
                ? 'í† ë¡  ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ'
                : 'ë‹¤ìš´ë¡œë“œ',
              isConversation
                ? 'Download Reaction Voice'
                : isPhotoAnalysisAudio
                ? 'Download Photo Analysis Audio'
                : isDebateAudio
                ? 'Download Debate Audio'
                : 'Download',
              isConversation
                ? 'ä¸‹è½½Reaction Voice'
                : isPhotoAnalysisAudio
                ? 'ä¸‹è½½ç…§ç‰‡åˆ†æéŸ³é¢‘'
                : isDebateAudio
                ? 'ä¸‹è½½è¾©è®ºéŸ³é¢‘'
                : 'ä¸‹è½½'
            )}
          </span>
          <span className="sm:hidden">
            {getText('ë‹¤ìš´ë¡œë“œ', 'Download', 'ä¸‹è½½')}
          </span>
        </Button>
      </div>

      {/* íŠ¸ë™ ì •ë³´ */}
      <div className="text-center space-y-1">
        <h3 className="font-medium text-gray-900 truncate text-sm sm:text-base">
          {title.length > 40 ? title.substring(0, 40) + '...' : title}
        </h3>
        <div className="flex items-center justify-center space-x-2">
          <p className="text-xs sm:text-sm text-gray-500">
            {getText(
              isConversation
                ? `ë‚´ë ˆì´í„° + ${character} ë°˜ì‘`
                : isPhotoAnalysisAudio
                ? `${character}ê°€ ì‚¬ì§„ ë¶„ì„`
                : isDebateAudio
                ? `${character} í† ë¡ `
                : `${character}ê°€ ë‚´ë ˆì´ì…˜`,
              isConversation
                ? `Narrator + ${character} reactions`
                : isPhotoAnalysisAudio
                ? `${character} analyzes photo`
                : isDebateAudio
                ? `${character} debate`
                : `${character} narrates`,
              isConversation
                ? `æ—ç™½ + ${character} ååº”`
                : isPhotoAnalysisAudio
                ? `${character} åˆ†æç…§ç‰‡`
                : isDebateAudio
                ? `${character} è¾©è®º`
                : `${character} æ—ç™½`
            )}
          </p>
          <Sparkles className="w-2 h-2 sm:w-3 sm:h-3 text-purple-500" />
          <span className="text-xs font-medium text-purple-600">
            {audioError
              ? getText('Audio Error', 'Audio Error', 'éŸ³é¢‘é”™è¯¯')
              : isReactionVoice
              ? 'Reaction Voice MP3'
              : isSpeechPlaying
              ? getText(
                  'Live Browser Voice',
                  'Live Browser Voice',
                  'å®æ—¶æµè§ˆå™¨è¯­éŸ³'
                )
              : isPhotoAnalysisAudio
              ? getText(
                  'Photo Analysis Audio',
                  'Photo Analysis Audio',
                  'ç…§ç‰‡åˆ†æéŸ³é¢‘'
                )
              : isDebateAudio
              ? getText(
                  'Mixed Debate Audio',
                  'Mixed Debate Audio',
                  'æ··åˆè¾©è®ºéŸ³é¢‘'
                )
              : getText(
                  'Enhanced Character Voice',
                  'Enhanced Character Voice',
                  'å¢å¼ºè§’è‰²è¯­éŸ³'
                )}
          </span>
        </div>
      </div>

      {/* ê³µìœ  ë©”ë‰´ ì™¸ë¶€ í´ë¦­ ì‹œ ë‹«ê¸° */}
      {showShareMenu && (
        <div
          className="fixed inset-0 z-40"
          onClick={() => setShowShareMenu(false)}
        />
      )}
    </div>
  );
}